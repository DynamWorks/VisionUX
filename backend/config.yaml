# Server Configuration
api:
  host: ${VIDEO_ANALYTICS_API_HOST:-0.0.0.0}  # Bind address (0.0.0.0 for all interfaces)
  port: ${VIDEO_ANALYTICS_API_PORT:-8000}      # API server port
  debug: ${VIDEO_ANALYTICS_API_DEBUG:-false}    # Enable debug mode
  cors_origins: ${VIDEO_ANALYTICS_CORS_ORIGINS:-"*"}  # CORS allowed origins

websocket:
  host: ${VIDEO_ANALYTICS_WS_HOST:-0.0.0.0}    # WebSocket bind address
  port: ${VIDEO_ANALYTICS_WS_PORT:-8001}        # WebSocket server port
  debug: ${VIDEO_ANALYTICS_WS_DEBUG:-false}      # Enable WebSocket debug mode
  max_buffer_size: 104857600  # 100MB in bytes

rerun:
  host: ${VIDEO_ANALYTICS_HOST_IP:-localhost}    # Rerun server host
  web_port: ${VIDEO_ANALYTICS_RERUN_WEB_PORT:-9090}  # Web viewer port
  ws_port: ${VIDEO_ANALYTICS_RERUN_WS_PORT:-4321}    # WebSocket port
  blueprint:
    layout: "vertical"  # Main layout orientation
    views:
      - type: "spatial2d"
        name: "Video Feed"
        origin: "world/video/stream"
        settings:
          fit_to_content: true
          background_color: [26, 26, 26]  # Dark background (RGB)
      - type: "text_log"
        name: "Events"
        origin: "world/events"
        settings:
          max_lines: 1000
          show_timestamps: true
                                                                                   
frontend:   
  host: localhost
  port: 8501
  title: "Video Analytics Dashboard"
  
backend:
  host: localhost
  port: 8000
  workers: 4

# Processing Configuration
processing:
  sample_rate: 30
  max_workers: 4
  confidence_threshold: 0.5
  batch_size: 8

# Model Configuration  
models:
  clip:
    name: "openai/clip-vit-base-patch32"
    local_path: "backend/models/clip"
  yolo:
    name: "yolov8x.pt"
    local_path: "backend/models/yolo"
  traffic_signs:
    name: "yolov8n.pt"
    local_path: "backend/models/traffic_signs"

# Service Configuration
services:
  openai:
    model: gpt-4-vision-preview-v2
    max_tokens: 500
    temperature: 0.7
  
  scene_analysis:
    model: "gpt-4o-mini"
    max_tokens: 500
    temperature: 0.7
    
  detection:
    model: yolov8n.pt
    confidence: 0.25
    sample_rate: 30
    
  rag:
    embeddings_model: "sentence-transformers/all-mpnet-base-v2"
    chunk_size: 1000
    chunk_overlap: 200

# Storage Configuration
storage:
  base_path: "tmp_content"
  max_age_hours: 24
  subdirs:
    - uploads
    - analysis 
    - chat_history
    - visualizations

# Logging Configuration
logging:
  level: INFO
  file: video_analytics.log
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
