# Vision LLM Environment Configuration
# Copy this file to .env and adjust values as needed

# API Configuration
API_HOST=127.0.0.1          # API server bind address
API_PORT=8000               # API server port
API_DEBUG=false             # Enable API debug mode
API_CORS_ORIGINS=*         # CORS allowed origins

# WebSocket Configuration
WS_HOST=localhost          # WebSocket server host
WS_PORT=8000              # WebSocket server port
WS_DEBUG=false            # Enable WebSocket debug mode
WS_SSL=false             # Enable SSL for WebSocket
WS_KEY=                  # Path to SSL key file
WS_CERT=                # Path to SSL certificate file
WS_PING_TIMEOUT=60      # WebSocket ping timeout in seconds
WS_PING_INTERVAL=25     # WebSocket ping interval in seconds
WS_BUFFER_SIZE=104857600 # WebSocket buffer size in bytes

# Storage Configuration
STORAGE_PATH=tmp_content  # Base path for temporary content storage
MAX_UPLOAD_SIZE=100      # Maximum upload size in MB
CLEANUP_INTERVAL=24      # Cleanup interval in hours
MAX_FILE_AGE=168        # Maximum file age in hours (7 days)

# Logging Configuration
LOG_LEVEL=INFO          # Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_FILE=logs/vision_llm.log  # Log file path
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here      # Your OpenAI API key
OPENAI_API_BASE=https://api.openai.com/v1  # OpenAI API base URL
OPENAI_MODEL=gpt-4o-mini             # OpenAI model to use

# Gemini Configuration  
GEMINI_API_KEY=your-api-key-here     # Your Gemini API key
GEMINI_MODEL=gemini-1.5-flash        # Gemini model to use

# Video Processing Configuration
MAX_FPS=30              # Maximum frames per second
TARGET_RESOLUTION=1280x720  # Target video resolution
JPEG_QUALITY=85         # JPEG compression quality (0-100)
FRAME_BUFFER_SIZE=30    # Maximum frames to buffer
